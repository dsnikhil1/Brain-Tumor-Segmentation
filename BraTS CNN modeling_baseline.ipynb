{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "from tifffile import imsave\n",
    "import splitfolders\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import segmentation_models as sm\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import MSELoss\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "mmscaler = MinMaxScaler()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import copy\n",
    "import cv2\n",
    "import glob\n",
    "import cv2\n",
    "import os \n",
    "from os import path\n",
    "from skimage.color import lab2rgb\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import MaxPool3d\n",
    "from torch.nn import AvgPool3d\n",
    "from torch.nn import Linear, ReLU, MSELoss, Sequential, Conv2d, Conv3d, ConvTranspose3d, BatchNorm3d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, ConvTranspose2d\n",
    "from torch.optim import Adam, SGD\n",
    "from math import log10, sqrt\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity\n",
    "import argparse\n",
    "import imutils\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_images = 'BraTS2020_TrainingData/input_data_128/train/images'\n",
    "train_path_masks = 'BraTS2020_TrainingData/input_data_128/train/masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_images = []\n",
    "for file in os.listdir(train_path_images):\n",
    "    img = np.load(train_path_images+'/'+file)\n",
    "    all_train_images.append(img)\n",
    "all_train_images = np.asarray(all_train_images)\n",
    "all_train_masks = []\n",
    "for file in os.listdir(train_path_masks):\n",
    "    img = np.load(train_path_masks+'/'+file)\n",
    "    all_train_masks.append(img)\n",
    "all_train_masks = np.asarray(all_train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_images = torch.tensor(all_train_images)\n",
    "all_train_masks = torch.tensor(all_train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(Convnet, self).__init__()\n",
    "\n",
    "        self.convolution_layers = Sequential(\n",
    "            Conv3d(3, 8, kernel_size=3, stride=1, padding=1),\n",
    "            MaxPool3d(kernel_size=2,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            Conv3d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            MaxPool3d(kernel_size=2,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            Conv3d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            MaxPool3d(kernel_size=2,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            Conv3d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            MaxPool3d(kernel_size=2,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            Conv3d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            MaxPool3d(kernel_size=2,stride=2),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "        self.deconvolution_layers = Sequential(\n",
    "            ConvTranspose3d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            ConvTranspose3d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            ConvTranspose3d(32, 16, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            ConvTranspose3d(16, 8, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            ConvTranspose3d(8, 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.convolution_layers(x)\n",
    "        x = self.deconvolution_layers(x)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\"\n",
    "print(\"Device\", device)\n",
    "\n",
    "\n",
    "batch_size = 2\n",
    "num_epochs = 5\n",
    "N=258\n",
    "learning_rate = 0.01\n",
    "batches = int(N/batch_size)\n",
    "\n",
    "\n",
    "model = Convnet()\n",
    "model = model.float()\n",
    "model.to(device)\n",
    "\n",
    "train_data=copy.deepcopy(all_train_images)\n",
    "train_data = train_data.to(device)\n",
    "print(\"Printing train data shape\")\n",
    "print(train_data.shape)\n",
    "train_mask = all_train_masks.to(device)\n",
    "print(\"Printing train mask shape\")\n",
    "print(train_mask.shape)\n",
    "#test_data = copy.deepcopy(test_L)\n",
    "#test_data = test_data.to(device)\n",
    "#print(\"Printing test data shape\")\n",
    "#print(test_data.shape)\n",
    "#test_ab = test_ab.to(device)\n",
    "#print(\"Printing test ab shape\")\n",
    "#print(test_ab.shape)\n",
    "\n",
    "\n",
    "error = nn.CrossEntropyLoss() # This works well with the linear output layer\n",
    "\n",
    "dice_l = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25])) #dice loss\n",
    "focal_l = sm.losses.CategoricalFocalLoss() #focal loss\n",
    "total_l = dice_l + (1 * focal_l) #total loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(\"batch_size:\",batch_size)\n",
    "print('num_epochs:',num_epochs)\n",
    "print(\"learning_rate:\",learning_rate)\n",
    "print(\"batches:\",batches)\n",
    "print(\"optimizer:\",'Adam')\n",
    "print(\"Loss function:\",\"CrossEntropyLoss\")\n",
    "print(model)\n",
    "\n",
    "loss_hist = np.zeros(num_epochs)\n",
    "#loss_test_hist = np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for index in range(batches):\n",
    "        patterns = train_data[index*batch_size:(index+1)*batch_size]\n",
    "        labels = train_mask[index*batch_size:(index+1)*batch_size]\n",
    "        \n",
    "        train = Variable(patterns.view(batch_size,3,128,128,128))\n",
    "        train = train.float()\n",
    "        masks = Variable(labels.view(batch_size,4,128,128,128))\n",
    "        masks = masks.float()\n",
    "        \n",
    "        #print(\"printing all labels shape\")\n",
    "        #print(labels.shape)\n",
    "        # Forward pass \n",
    "        outputs = model(train)\n",
    "        #loss = error(outputs, masks)\n",
    "        loss = total_l\n",
    "        \n",
    "\n",
    "        # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Propagating the error backward\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizing the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Saving the loss for visualization\n",
    "        loss_hist[epoch] += loss.data\n",
    "        \n",
    "\n",
    "    #test_total\n",
    "    #patterns = test_data\n",
    "    #labels = test_ab\n",
    "    #outputs = model(patterns)\n",
    "    #is_correct = torch.subtract(labels,outputs)\n",
    "    #loss_test_hist[epoch] += (is_correct.sum()*is_correct.sum())/test_size\n",
    "\n",
    "    #if epoch%10==0:\n",
    "    print(\"Epoch: {}, Loss: {:.7f}\".format( epoch, loss_hist[epoch]))\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss_hist)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Cross Entropy Loss\")\n",
    "plt.title(\"Brain Tumor Segmentation\")\n",
    "plt.legend([\"Training Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image=all_train_images[0]\n",
    "test_image=Variable(test_image.view(1,3,128,128,128))\n",
    "test_image=test_image.float()\n",
    "test_image=test_image.to(device)\n",
    "test_image_output=model(test_image)\n",
    "test_image_output=test_image_output.squeeze()\n",
    "f = test_image_output.detach()\n",
    "p=np.array(f.cpu())\n",
    "data = np.moveaxis(p, 0, 3)\n",
    "test_seg_mask=np.argmax(data, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "or_seg_mask = np.argmax(all_train_masks[0],axis=3)\n",
    "plt.imshow(or_seg_mask[:,:,n_slice])\n",
    "plt.title('Original Segmentation Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
